<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Model preparation for Hailo</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f9;
            color: #333;
        }
        header {
            background: #333;
            color: #fff;
            padding: 10px 20px;
            text-align: center;
        }
        nav {
            background: #555;
            padding: 10px;
        }
        nav a {
            color: #fff;
            text-decoration: none;
            margin-right: 10px;
        }
        nav a:hover {
            text-decoration: underline;
        }
        main {
            padding: 20px;
            margin-bottom: 50px;
        }
        section {
            margin-bottom: 20px;
        }
        footer {
            text-align: center;
            padding: 10px;
            background: #333;
            color: #fff;
            position: fixed;
            bottom: 0;
            width: 100%;
        }
    </style>
</head>
<body>
    <header>
        <h1>Model preparation for Hailo</h1>
    </header>

    <nav>
        <a href="#section1">Translating</a>
        <a href="#section2">Parsing</a>
        <a href="#section3">Optimization</a>
        <a href="#section4">Compilation</a>
        <a href="#section5">Usage</a>
    </nav>

    <main>
        <section id="section1">
            <h2>Translating</h2>
            <p>
              First, the model needs to be parsed from a .pth format into onnx, run <a href="https://github.com/audiblemaple/AlertWatch/blob/main/face_landmarks_detection/conversion/convert_pth_to_onnx.py">convert_pth_to_onnx.py</a> with the pytorch model.
            </p>
        </section>

        <section id="section2">
            <h2>Parsing</h2>
            <p>
              Use the translated .onnx model file to parse it to a .har (Hailo archive) file.
              Go to <a href="https://github.com/audiblemaple/AlertWatch/tree/main/hailo/1.parsing">/hailo</a>
            </p>
          Run:<br>
            <code>
                . parse_model.sh "path_to_.onnx_model"
            </code>
        </section>

        <section id="section3">
            <h2>Optimization</h2>
            <p>
                To optimize the model we first need to create the calibration set so the model will know what data types to expect as input and calibrates the weights correctly when optimizing.
            </p>
            Go to <a href="https://github.com/audiblemaple/AlertWatch/tree/main/hailo/2.create_calibration_setl">hailo/2.create_calibration_set_Final</a>
            <br>
            Run: <br>
            <code>
                # Create a directory with preprocessed faces resized to 224x224 as the model expects
                <br>
                python3 preprocess_images.py
                <br> <br>
                # create the calibration set as a .npy array file
                <br>
                python3 prepare_calibration_set_FLOAT32.py
                <br>
            </code>
            Go to <a href="https://github.com/audiblemaple/AlertWatch/tree/main/hailo/3.optimization">hailo/3.optimization_Final</a>
            <br>
            Run:
            <br>
            <code>
                # Optimize the model
                <br>
                . optimize_model.sh --hw-arch 'hardware architecture' --calib-set-path 'calibration set' --output-har-path 'output file name' 'input file
                <br>
                <br>
                # For help run
                <br>
                . optimize_model.sh
            </code>
        </section>

        <section id="section4">
            <h2>Compilation</h2>
            Go to <a href="https://github.com/audiblemaple/AlertWatch/tree/main/hailo/4.compilation">hailo/4.compilation</a>
            <br>
            Run:
            <br>
            <code>
                # Compile the model
                <br>
                . compile_model.sh --hw-arch 'hardware architecture' --output-dir output 'input_file'
                <br>
                <br>
                # For help run
                <br>
                . compile_model.sh
            </code>
        </section>

        <section id="section5">
            <h2>Usage</h2>
            Copy the compiled .hef model to the main detector file directory and specify the path to the model in the code
        </section>
    </main>

    <footer>
        <p>Lior Jigalo - Alertwatch</p>
    </footer>
</body>
</html>

